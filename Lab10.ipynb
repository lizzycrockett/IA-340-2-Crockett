{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18be3dc5-5374-45e3-b39c-6bcddeb7d033",
   "metadata": {},
   "source": [
    "# Lab 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2295a-98ae-415a-9811-e18216e97d9c",
   "metadata": {},
   "source": [
    "## Install Python Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94927e5e-fc4c-4ebe-b110-82147f087b31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d7019-6523-4488-b104-30aad3c49ac9",
   "metadata": {},
   "source": [
    "## Secrets Manager Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21601d78-8651-4705-9277-143695326d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a8dfa-8e9f-4182-b1ba-c8877070bec8",
   "metadata": {},
   "source": [
    "## Import Python Libraries and Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da65775-f8f7-4266-a2de-b7d6da6900d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d05b4-59a0-4688-b9c5-dee5ba76b7f3",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23ad77a-0cde-4318-ab6d-b31b73aa42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_collection #use or create a collection named tweet_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d5489c-7a5c-4efe-8092-82547237f923",
   "metadata": {},
   "source": [
    "## Utility Funcitons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19570a4f-5e96-41f6-82ff-fa42e2ae18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(url_pattern, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b5b51b-e439-40ee-afa2-acc9ec9feea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model= 'text-embedding-3-small'\n",
    "\n",
    "def get_embedding(text):\n",
    "\n",
    "    try:\n",
    "        embedding = client.embeddings.create(input=text, model=embedding_model).data[0].embedding\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2faff761-9e7e-49f9-bcd0-f3731d509f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(query):\n",
    "\n",
    "    query_embedding = get_embedding(query)\n",
    "    if query_embedding is None:\n",
    "        return \"Invalid query or embedding generation failed.\"\n",
    "    # Define the vector search pipeline\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": \"tweet_vector\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"path\": \"tweet.embedding\",\n",
    "                \"numCandidates\": 1000,  # Number of candidate matches to consider\n",
    "                \"limit\": 10  # Return top 10 matches\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,  # Exclude the _id field\n",
    "                \"tweet.text\": 1 # return tweet text\n",
    "\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = tweet_collection.aggregate(pipeline)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505b6fa-d2d5-4cd1-8528-bb23cf6dec2d",
   "metadata": {},
   "source": [
    "## Tweets Embedding \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77b98ae-a0fe-411f-a993-cda26d99561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7c1a6264be490ea2be21209b89f331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tweets = tweet_collection.find()\n",
    "\n",
    "for tweet in tqdm(list(tweets)):\n",
    "    try:\n",
    "        tweet_embedding = get_embedding(clean_tweet(tweet['tweet']['text']))\n",
    "    #     print(tweet_embedding)\n",
    "\n",
    "        tweet_collection.update_one(\n",
    "            {'tweet.id':tweet['tweet']['id']},\n",
    "            {\"$set\":{'tweet.embedding':tweet_embedding}}\n",
    "        )\n",
    "    except:\n",
    "        print(f\"\"\"error in embedding tweet {tweet['tweet']['id']}\"\"\")\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac80cc-8c8c-4b25-9417-459b4ab1bbef",
   "metadata": {},
   "source": [
    "## Create a Vector Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba96d32-cf8a-4d65-8238-1754131da8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New search index named tweet_vector is building.\n",
      "Polling to check if the index is ready. This may take up to a minute.\n",
      "tweet_vector is ready for querying.\n"
     ]
    }
   ],
   "source": [
    "from pymongo.operations import SearchIndexModel\n",
    "import time\n",
    "\n",
    "search_index_model = SearchIndexModel(\n",
    "  definition={\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"type\": \"vector\",\n",
    "      \"path\": \"tweet.embedding\",\n",
    "      \"numDimensions\": 1536,\n",
    "      \"similarity\": \"cosine\"\n",
    "    }\n",
    "  ]\n",
    "},\n",
    "  name=\"tweet_vector\",\n",
    "  type=\"vectorSearch\"\n",
    "\n",
    ")\n",
    "result = tweet_collection.create_search_index(model=search_index_model)\n",
    "print(\"New search index named \" + result + \" is building.\")\n",
    "# Wait for initial sync to complete\n",
    "print(\"Polling to check if the index is ready. This may take up to a minute.\")\n",
    "predicate=None\n",
    "\n",
    "if predicate is None:\n",
    "  predicate = lambda index: index.get(\"queryable\") is True\n",
    "\n",
    "while True:\n",
    "  indices = list(tweet_collection.list_search_indexes(result))\n",
    "  if len(indices) and predicate(indices[0]):\n",
    "\n",
    "    break\n",
    "  time.sleep(5)\n",
    "\n",
    "print(result + \" is ready for querying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167340ee-27bf-47a8-b552-89e3cac7de18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple holy shit https://t.co/w84kB41syP\n",
      "RT @soulsyo2020: this apple...\n",
      "\n",
      "#radioapple https://t.co/7z0hLP68qm\n",
      "@alinur_md apple ðŸª ðŸŒº\n",
      "@alinur_md apple ðŸŒŸ ðŸ’¼\n",
      "ðŸŽ\n",
      "\"APPLE\"  TOWA TEI  feat. SHEENA RINGO ( MV with Gemini ) https://t.co/jvz2TnBC6s @YouTubeã‚ˆã‚Š\n",
      "@alinur_md apple ðŸŽŠ ðŸš© ðŸŒˆ\n",
      "@PolskaF00 I JUST FINISHED DEAD APPLE\n",
      "@NoDMsPerfavore Wine and Apple Juice\n",
      "#iPhone8Plusã€€å¾©æ´»å¸Œæœ›ã—ã¾ã™ #apple ã•ã‚“\n",
      "@applejuiceseeds @swingthatdoe @skytown05 Your name is apple juice seeds, you have a yarn ps3 game page, and you stan the little mermaid, I know you arent talking about â€œbig boyâ€ anything.\n"
     ]
    }
   ],
   "source": [
    "user_query = 'apple'\n",
    "\n",
    "for tweet in vector_search(user_query):\n",
    "    print(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777f3d73-1c6e-48c1-9e5a-cdf709affbab",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation (RAG) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "307b597f-efc2-4d60-858b-3b1b8986b28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "delimiter = '###'\n",
    "chat_model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [{\"role\": \"system\", \"content\": \"\"\" you are a chatbot, answer user questions based on the returned tweets.\"\"\"}]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    tweets = vector_search(prompt)\n",
    "    chat_history.append({\"role\": \"system\", \"content\": f\" here the returned tweets delimited by {delimiter}{tweets}{delimiter}\"})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=chat_model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68a58b0a-d606-4b49-bff0-8059a3b8a2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    print(f\"Chatbot: {reply}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
